{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Data taken up from Movielens dataset.\n",
    "USing Python, we would be seeing which movie is similar to STAR WARS\n",
    "We'll be working with movie names and not IDs \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['userId', 'movieId', 'rating']\n",
    "rating = pd.read_csv('E://Gaurav/ML_Dataset/movie_lens_data/rating.csv', names = r_cols, usecols = range(3))\n",
    "\n",
    "m_cols = ['movieId','title']\n",
    "movies = pd.read_csv('E://Gaurav/ML_Dataset/movie_lens_data/movie.csv', names = m_cols, usecols = range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.merge(rating,movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of Empty DataFrame\n",
       "Columns: [userId, movieId, rating, title]\n",
       "Index: []>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pivot table command in data frame - this will construct a user/movie rating matrix\n",
    "# matrix of every movie - index - userid, columsn- movie title\n",
    "\n",
    "movie_Ratings = rating.pivot_table(index = ['userid'],columns = ['title'],values = 'rating')\n",
    "\n",
    "# Such type of matrix is useful for both item based as well  as user based collborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we specifically want the users who voted for Black Sunday:\n",
    "\n",
    "Star_Wars_rating = movie_Ratings['Star Wars (1977)']\n",
    "Star_Wars_rating.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we shall find correlation of Black_sunday movie with every other movie in movie_ratings which is very important to produce recommendations.\n",
    "# Also dropping the ones with 'NaN'\n",
    "\n",
    "similar_movies = movie_Ratings.corrwith(Star_Wars_rating)\n",
    "similar_movies = similar_movies.dropna()\n",
    "dataframe = pd.dataframe(similar_movies)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the result with similarty score\n",
    "\n",
    "similar_movies.order(ascending = False)\n",
    "\n",
    "## uhhhh... what was this ????? We got fairly obscure movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"The main reason that we got suh a result is - we took into consideration the movies that were watched by just a handful of people.\n",
    "Hence, we shall cosntruct a new dataframe by counting the votes each movie got along with the avg rating so as to reduce the chances of spurious results.\"\"\"\n",
    "\n",
    "moviestats = rating.groupby('title').agg({'rating': [np.size, np.mean]})\n",
    "moviestats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Since our main aim is to egt rid of spurious data, so we get rid of movies rated by less than 100 people\"\"\"\n",
    "\n",
    "popularmovies = moviestats['rating']['size'] >=100\n",
    "moviestats[popularmovies].sort_values([('rating','mean')], ascending = False) [:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Now we shall create our final data frame. we shall join this data with our original data frame to get the movies similar to star wars (and get the similarity score too)\"\"\"\n",
    "\n",
    "\n",
    "df = moviestats[popularmovies],join(pd.Dataframe(similar_movies, columns=['similarity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['similarity'], ascedending=False) [:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Conclusion: Although we got a data which looks better than previosu one, but still can be refined by taking different thresholds (I took 100 as count of rating, we can take 120 or 130 for even better results)\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For a true Item based Recommendation system, we shall change some of teh steps done earlier.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_Ratings = rating.pivot_table(index = ['userid'],columns = ['title'],values = 'rating')\n",
    "user_Ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we shall find correlation for EVERY movie, with every other movie\n",
    "\n",
    "corr_matrix = user_Ratings.corr\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Again we got some spurious results of the movies wich are no highly correlated plus the ones which are correlated with themselves\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = user_Ratings.corr(method = 'pearson', min_periods=100)\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now since we need to Recommend movie to people, we created a fake person for whom we need to recommend.\n",
    "\n",
    "#added a fake id (0) , a person who liked movies like star wars, teh empire strikes back, but does like the romantic ones.\n",
    "\n",
    "myratings = user_Ratings.loc[0].dropna()\n",
    "myratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_Candidates = pd.Series()\n",
    "\n",
    "for i in range(0, len(myratings.index)):\n",
    "    print \"Adding similarities for \" + myRatings.index[i] + \"...\"\n",
    "    #Retreiving similar movies\n",
    "    sims = corr_matrix[myratings.index[i]].dropna()\n",
    "    #Scaling the similarity by how well I rated this movie\n",
    "    sims = sims.map(lambda x: x * myratings[i])\n",
    "    # Add this score to list of similarity candidates\n",
    "    similar_Candidates = similar_Candidates.append(sims)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting and printing the results:\n",
    "\n",
    "similar_Candidates.sort_values(inplace = True, ascending = False)\n",
    "print similar_Candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are geting duplicates, we shall use group by function to see the movie that is similar to more than 1 and count and get a stronf recommendation score\n",
    "\n",
    "similar_Candidates = similar_Candidates.groupby(similar_Candidates.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_Candidates.sort_values(inplace = True, ascending = False)\n",
    "print similar_Candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another important thing to remember : Filter out movies that the person has already seen, coz recommending a movie that someone has already watched isnt helpful for him.\n",
    "\n",
    "filtersimilarities = similar_Candidates.drop(myratings.index)\n",
    "filtersimilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use correlations other than pearson\n",
    "# Detect the outliers (some users rated huge amiunt of movie which might bring dispropotionate results)\n",
    "# always take into consideration business perspective (sometimes instincts too)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
